{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPPA\n",
    "\n",
    "## clear the workspace and configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/96/75gqgq_s2lz7zdh6kxtks3h40000gn/T/ipykernel_10446/2732267496.py:3: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  get_ipython().magic('reset -sf')\n"
     ]
    }
   ],
   "source": [
    "# clear the workspace\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')\n",
    "\n",
    "subset_test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path:  /Users/cheye/Desktop/new_yc/projects/IPPA/scripts\n",
      "data file path:  /Users/cheye/Desktop/new_yc/projects/IPPA/scripts/../data/smp_2019\n",
      "data image path:  /Users/cheye/Desktop/new_yc/projects/IPPA/scripts/../data/smp_2019/images\n",
      "number of images:  248558\n",
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print(\"current path: \", current_path)\n",
    "\n",
    "data_file_path = os.path.join(current_path, \"..\", \"data\", \"smp_2019\")\n",
    "print(\"data file path: \", data_file_path)\n",
    "\n",
    "data_image_path = os.path.join(data_file_path, \"images\")\n",
    "print(\"data image path: \", data_image_path)\n",
    "\n",
    "images = os.listdir(data_image_path)\n",
    "images = [image for image in images if image.endswith(\".jpg\")]\n",
    "print(\"number of images: \", len(images))\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)\n",
    "\n",
    "random.seed(42)\n",
    "if subset_test:\n",
    "    images = random.sample(images, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "                                                                                          img_path  label\n",
      "0  /Users/cheye/Desktop/new_yc/projects/IPPA/data/smp_2019/images/7645_16254807804_dfa939b058.jpg   9.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "user_additional         = os.path.join(data_file_path, \"user_additional.csv\")\n",
    "train_file_dir          = os.path.join(data_file_path, \"train_all_json\")\n",
    "img_url_file            = os.path.join(data_file_path, \"img_url.txt\")\n",
    "\n",
    "train_additional        = os.path.join(train_file_dir, \"train_additional_information.json\")\n",
    "train_img               = os.path.join(train_file_dir, \"train_img_filepath.txt\")\n",
    "train_label             = os.path.join(train_file_dir, \"train_label.txt\")\n",
    "\n",
    "with open(train_additional) as f:\n",
    "    train_additional = json.load(f)\n",
    "train_additional        = pd.DataFrame(train_additional)\n",
    "img_url                 = pd.read_csv(img_url_file, sep=\"\\t\", header=None)\n",
    "img_url.columns         = [\"url\", \"src\"]\n",
    "data                    = pd.concat([train_additional, img_url], axis=1)\n",
    "with open(train_label) as f:\n",
    "    train_labels = pd.read_csv(f, header=None)\n",
    "train_labels.columns    = [\"label\"]\n",
    "data                    = pd.concat([data, train_labels], axis=1)\n",
    "img_names               = images\n",
    "img_names               = [i.replace(\"_\", \"/\", 1) for i in img_names if i.endswith(\".jpg\")]\n",
    "img_names               = [\"https://live.staticflickr.com/\" + i for i \\\n",
    "                           in img_names if i.endswith(\".jpg\")]\n",
    "img_names               = pd.DataFrame(img_names, columns=[\"src\"])\n",
    "data                    = pd.merge(data, img_names, on=[\"src\"])\n",
    "data[\"src\"]         = data[\"src\"].apply(lambda x: os.path.join( \\\n",
    "    data_image_path, x.replace(\"https://live.staticflickr.com/\", \"\").replace(\"/\", \"_\")))\n",
    "data[\"src\"]             = data[\"src\"].apply(lambda x: os.path.abspath(x))\n",
    "\n",
    "data = data[[\"src\", \"label\"]]\n",
    "data = data.rename(columns={\"src\": \"img_path\"})\n",
    "del data_file_path, data_image_path, images, user_additional\n",
    "del train_file_dir, img_url_file, train_additional, train_img\n",
    "del train_label, img_url, train_labels, img_names, current_path, f\n",
    "gc.collect()\n",
    "\n",
    "print(\"data:\\n\", data.head(1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmclassification/v0/efficientnet/efficientnet-b0_3rdparty_8xb32_in1k_20220119-a7e2a0b1.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mmpretrain import get_model\n",
    "\n",
    "model = get_model('efficientnet-b0_3rdparty_8xb32_in1k', pretrained=True)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]  # 假设img_path在第一列\n",
    "        image = Image.open(img_path).convert('RGB')  # 加载图像并确保是RGB格式\n",
    "        label = self.dataframe.iloc[idx, 1]  # 假设label在第二列\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class ConvertToRGB:\n",
    "    def __call__(self, image):\n",
    "        return image.convert('RGB')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ConvertToRGB(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(dataframe=data, transform=transform)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in data_loader:\n",
    "        results = model(inputs)\n",
    "        outputs.append(results)\n",
    "\n",
    "outputs = torch.cat(outputs, dim=0)\n",
    "_, preds = torch.max(outputs, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
